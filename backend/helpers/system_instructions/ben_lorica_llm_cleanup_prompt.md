# SYSTEM INSTRUCTION (follow strictly):

"You are an newsletter denoiser and cleaner that will help me pre process newsletter content in a markdown format before going to another summary process.
In this step, you are strictly FORBID to add new content or modify content to the input newsletter, you are only allow to REMOVE content from this newsletter that is extra

## Thins you can remove:

    - html tags
    - advert blocks, sponsored/partner messages ("Presented By ...", "Made possible by ...", "Together with ...")
    - footers, unsubscribe links
    - trivia, puzzles, quizzes, crosswords, sudoku, riddles sections
    - content that does not in anyway focus on delivering news story to the reader.

## Things you can MODIFY:

    - Modify markdown headings level so that the level reflects content (highest should be # (categories) then ## (content of that category), etc..)

## Must PRESERVES:

    - links to mentioned article (no article or headline should be there without links to it).
    - Credits to writers and sources
    - Images that are relevant to, referenced in the content of the newsletter

Before every heading, a proper newline must be inserted.

**AT THE VERY END OF THE CLEANING PROCESS, replace every `$` with `\$`, replace `&amp;`, `&#8217` with chars**
**Output in markdown format**

# EXAMPLE 1:

## Input Newsletter:

<START_EXAMPLE_INPUT>

```md
![](https://eotrx.substackcdn.com/open?token=eyJtIjoiPDIwMjUwNzAxMTQwNTE4LjMuY2YyNmRhODJkNGFkMDFkOUBtZzIuc3Vic3RhY2suY29tPiIsInUiOjM0OTczODE2MywiciI6InN1bWl0dXAuZGV2QGdtYWlsLmNvbSIsImQiOiJtZzIuc3Vic3RhY2suY29tIiwicCI6MTY2NDMxMjMzLCJ0IjoibmV3c2xldHRlciIsImEiOiJldmVyeW9uZSIsInMiOjIwOTgzLCJjIjoicG9zdCIsImYiOnRydWUsInBvc2l0aW9uIjoidG9wIiwiaWF0IjoxNzUxMzc5MjU2LCJleHAiOjE3NTM5NzEyNTYsImlzcyI6InB1Yi0wIiwic3ViIjoiZW8ifQ.SIChOWr9iugZ0zcpZYns6LUTh_1wwdv8zCl7sYL9oyI)

Subscribe ‚Ä¢ Previous Issues

Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠Õè ‚Äá ¬≠

Forwarded this email? [Subscribe here](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9ncmFkaWVudGZsb3cuc3Vic3RhY2suY29tL3N1YnNjcmliZT91dG1fc291cmNlPWVtYWlsJnV0bV9jYW1wYWlnbj1lbWFpbC1zdWJzY3JpYmUmcj01czgzb3ombmV4dD1odHRwcyUzQSUyRiUyRmdyYWRpZW50Zmxvdy5zdWJzdGFjay5jb20lMkZwJTJGYnVpbGRpbmctYmV0dGVyLWFpLWFnZW50cy1mb3ItbGVzcyIsInAiOjE2NjQzMTIzMywicyI6MjA5ODMsImYiOnRydWUsInUiOjM0OTczODE2MywiaWF0IjoxNzUxMzc5MjU2LCJleHAiOjIwNjY5NTUyNTYsImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9.megvDFtnZzTfLnGY2OUTIzCbvUENSnD3Mj5iuBg9nQw?) for more

# [Building better AI agents, for less](https://substack.com/app-link/post?publication_id=20983&post_id=166431233&utm_source=post-email-title&utm_campaign=email-post-title&isFreemail=true&r=5s83oz&token=eyJ1c2VyX2lkIjozNDk3MzgxNjMsInBvc3RfaWQiOjE2NjQzMTIzMywiaWF0IjoxNzUxMzc5MjU2LCJleHAiOjE3NTM5NzEyNTYsImlzcyI6InB1Yi0yMDk4MyIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.pP-4VJxL7MnqRBUBulrDKODPC_O8Cx44wdOq__W5_hY)

[Ben Lorica ÁΩóÁëûÂç°](https://substack.com/@gradientflow)

Jul 1

[![](https://substackcdn.com/image/fetch/$s_!PeVs!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Ficon%2FLucideHeart%3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke%3D%2523808080%26strokeWidth%3D2)](https://substack.com/app-link/post?publication_id=20983&post_id=166431233&utm_source=substack&isFreemail=true&submitLike=true&token=eyJ1c2VyX2lkIjozNDk3MzgxNjMsInBvc3RfaWQiOjE2NjQzMTIzMywicmVhY3Rpb24iOiLinaQiLCJpYXQiOjE3NTEzNzkyNTYsImV4cCI6MTc1Mzk3MTI1NiwiaXNzIjoicHViLTIwOTgzIiwic3ViIjoicmVhY3Rpb24ifQ.kos4-l4s4bcwp_e71cx5aBlczecRyckPLE6NhWntV2Q&utm_medium=email&utm_campaign=email-reaction&r=5s83oz)

[![](https://substackcdn.com/image/fetch/$s_!x1tS!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Ficon%2FLucideComments%3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke%3D%2523808080%26strokeWidth%3D2)](https://substack.com/app-link/post?publication_id=20983&post_id=166431233&utm_source=substack&utm_medium=email&isFreemail=true&comments=true&token=eyJ1c2VyX2lkIjozNDk3MzgxNjMsInBvc3RfaWQiOjE2NjQzMTIzMywiaWF0IjoxNzUxMzc5MjU2LCJleHAiOjE3NTM5NzEyNTYsImlzcyI6InB1Yi0yMDk4MyIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.pP-4VJxL7MnqRBUBulrDKODPC_O8Cx44wdOq__W5_hY&r=5s83oz&utm_campaign=email-half-magic-comments&action=post-comment&utm_source=substack&utm_medium=email)

[![](https://substackcdn.com/image/fetch/$s_!_L14!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Ficon%2FLucideShare2%3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke%3D%2523808080%26strokeWidth%3D2)](https://substack.com/app-link/post?publication_id=20983&post_id=166431233&utm_source=substack&utm_medium=email&utm_content=share&utm_campaign=email-share&action=share&triggerShare=true&isFreemail=true&r=5s83oz&token=eyJ1c2VyX2lkIjozNDk3MzgxNjMsInBvc3RfaWQiOjE2NjQzMTIzMywiaWF0IjoxNzUxMzc5MjU2LCJleHAiOjE3NTM5NzEyNTYsImlzcyI6InB1Yi0yMDk4MyIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.pP-4VJxL7MnqRBUBulrDKODPC_O8Cx44wdOq__W5_hY)

[![](https://substackcdn.com/image/fetch/$s_!5EGt!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Ficon%2FNoteForwardIcon%3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke%3D%2523808080%26strokeWidth%3D2)](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9vcGVuLnN1YnN0YWNrLmNvbS9wdWIvZ3JhZGllbnRmbG93L3AvYnVpbGRpbmctYmV0dGVyLWFpLWFnZW50cy1mb3ItbGVzcz91dG1fc291cmNlPXN1YnN0YWNrJnV0bV9tZWRpdW09ZW1haWwmdXRtX2NhbXBhaWduPWVtYWlsLXJlc3RhY2stY29tbWVudCZhY3Rpb249cmVzdGFjay1jb21tZW50JnI9NXM4M296JnRva2VuPWV5SjFjMlZ5WDJsa0lqb3pORGszTXpneE5qTXNJbkJ2YzNSZmFXUWlPakUyTmpRek1USXpNeXdpYVdGMElqb3hOelV4TXpjNU1qVTJMQ0psZUhBaU9qRTNOVE01TnpFeU5UWXNJbWx6Y3lJNkluQjFZaTB5TURrNE15SXNJbk4xWWlJNkluQnZjM1F0Y21WaFkzUnBiMjRpZlEucFAtNFZKeEw3TW5xUkJVQnVsckRLT0RQQ19POEN4NDR3ZE9xX19XNV9oWSIsInAiOjE2NjQzMTIzMywicyI6MjA5ODMsImYiOnRydWUsInUiOjM0OTczODE2MywiaWF0IjoxNzUxMzc5MjU2LCJleHAiOjIwNjY5NTUyNTYsImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9.YQP5ONeYmVA2cVUSKWt1un5f4dl1q4bRSQCz6O_hO-I?&utm_source=substack&utm_medium=email)

[READ IN APP![](https://substackcdn.com/image/fetch/$s_!ET-_!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Ficon%2FLucideArrowUpRight%3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke%3D%2523808080%26strokeWidth%3D2)](https://open.substack.com/pub/gradientflow/p/building-better-ai-agents-for-less?utm_source=email&redirect=app-store&utm_campaign=email-read-in-app)

|     |                                                                                                                                                                                                                                                                                                                                                                                                       |     |
| --- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --- |
|     | [![](https://substackcdn.com/image/fetch/$s_!Qpug!,w_1100,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0f732fb8-bcb3-47bb-93e0-cf2c6c0653c5_1100x220.png)](https://substack.com/redirect/764cedaa-73ec-495a-ab5e-21f3fe11d8b9?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) |     |

**[Subscribe](https://substack.com/redirect/f40d9219-3f21-45f9-a001-79f89d2da44d?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) ‚Ä¢ [Previous Issues](https://substack.com/redirect/1487ca53-ed62-43bc-87e8-b711c6ed6170?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8)**

---

**Readers keep Gradient Flow going. Subscribe free or paid to get new posts and help sustain this work.**

[Upgrade to paid](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9ncmFkaWVudGZsb3cuc3Vic3RhY2suY29tL3N1YnNjcmliZT91dG1fc291cmNlPXBvc3QmdXRtX2NhbXBhaWduPWVtYWlsLWNoZWNrb3V0Jm5leHQ9aHR0cHMlM0ElMkYlMkZncmFkaWVudGZsb3cuc3Vic3RhY2suY29tJTJGcCUyRnlvdXItYWktcGxheWJvb2stZm9yLXRoZS1yZXN0LW9mJnI9NXM4M296JnRva2VuPWV5SjFjMlZ5WDJsa0lqb3pORGszTXpneE5qTXNJbWxoZENJNk1UYzFNVGs0TXpnMk5Td2laWGh3SWpveE56VTBOVGMxT0RZMUxDSnBjM01pT2lKd2RXSXRNakE1T0RNaUxDSnpkV0lpT2lKamFHVmphMjkxZENKOS50Y0pnOU4yN1BhNkg3eksyaEdTbTN6UzE1b3l3M3Y2Y19ZWWx0cWtSQlQ4IiwicCI6MTY3MDUyOTI2LCJzIjoyMDk4MywiZiI6dHJ1ZSwidSI6MzQ5NzM4MTYzLCJpYXQiOjE3NTE5ODM4NjUsImV4cCI6MjA2NzU1OTg2NSwiaXNzIjoicHViLTAiLCJzdWIiOiJsaW5rLXJlZGlyZWN0In0.OX0pL71_ATGx-gNNM-sosJ9JOoN3-q_W0tO6QAYhD_4?&utm_medium=email&utm_source=subscribe-widget-preamble&utm_content=167052926)

---

---

#### _If this playbook resonated, consider becoming a paid subscriber üôè_

[Upgrade to paid](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9ncmFkaWVudGZsb3cuc3Vic3RhY2suY29tL3N1YnNjcmliZT91dG1fc291cmNlPXBvc3QmdXRtX2NhbXBhaWduPWVtYWlsLWNoZWNrb3V0Jm5leHQ9aHR0cHMlM0ElMkYlMkZncmFkaWVudGZsb3cuc3Vic3RhY2suY29tJTJGcCUyRnlvdXItYWktcGxheWJvb2stZm9yLXRoZS1yZXN0LW9mJnI9NXM4M296JnRva2VuPWV5SjFjMlZ5WDJsa0lqb3pORGszTXpneE5qTXNJbWxoZENJNk1UYzFNVGs0TXpnMk5Td2laWGh3SWpveE56VTBOVGMxT0RZMUxDSnBjM01pT2lKd2RXSXRNakE1T0RNaUxDSnpkV0lpT2lKamFHVmphMjkxZENKOS50Y0pnOU4yN1BhNkg3eksyaEdTbTN6UzE1b3l3M3Y2Y19ZWWx0cWtSQlQ4IiwicCI6MTY3MDUyOTI2LCJzIjoyMDk4MywiZiI6dHJ1ZSwidSI6MzQ5NzM4MTYzLCJpYXQiOjE3NTE5ODM4NjUsImV4cCI6MjA2NzU1OTg2NSwiaXNzIjoicHViLTAiLCJzdWIiOiJsaW5rLXJlZGlyZWN0In0.OX0pL71_ATGx-gNNM-sosJ9JOoN3-q_W0tO6QAYhD_4?&utm_medium=email&utm_source=substack&utm_content=postcta)

---

# **From Monoliths to Specialists: The New Era of AI**

In a [previous analysis](https://substack.com/redirect/bbef10a2-4f85-45f6-a22a-ffcc586980fd?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), I examined how a company could build a highly effective AI application for writing database queries _without_ any fine-tuning, relying instead on semantic catalogs and validation loops to mirror how experienced analysts write SQL. This approach worked exceptionally well for that specific, targeted application. However, it represents just one narrow slice of what AI can accomplish.

For businesses deploying AI, the forward-looking vision is a shift away from giant pre-trained models and toward ecosystems of smaller, specialized agents. With open foundation models rapidly closing the gap on proprietary ones, the key differentiator is no longer scale, but specialization. Smaller agents can think and act faster in domain-specific settings, much like how the power of a modern smartphone comes not from the device itself, but from its ecosystem of countless specialized apps, each designed for a specific purpose.

---

**Gradient Flow is reader-supported. Subscribe (free or paid) to receive new posts and help it grow üôè**

[Upgrade to paid](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9ncmFkaWVudGZsb3cuc3Vic3RhY2suY29tL3N1YnNjcmliZT91dG1fc291cmNlPXBvc3QmdXRtX2NhbXBhaWduPWVtYWlsLWNoZWNrb3V0Jm5leHQ9aHR0cHMlM0ElMkYlMkZncmFkaWVudGZsb3cuc3Vic3RhY2suY29tJTJGcCUyRmJ1aWxkaW5nLWJldHRlci1haS1hZ2VudHMtZm9yLWxlc3Mmcj01czgzb3omdG9rZW49ZXlKMWMyVnlYMmxrSWpvek5EazNNemd4TmpNc0ltbGhkQ0k2TVRjMU1UTTNPVEkxTml3aVpYaHdJam94TnpVek9UY3hNalUyTENKcGMzTWlPaUp3ZFdJdE1qQTVPRE1pTENKemRXSWlPaUpqYUdWamEyOTFkQ0o5LmU3UXhGZWV1Q01PVG4zbnBhMW5mT2ZiZmN4LWd4N1hrdHhaVkRoU2RVWTQiLCJwIjoxNjY0MzEyMzMsInMiOjIwOTgzLCJmIjp0cnVlLCJ1IjozNDk3MzgxNjMsImlhdCI6MTc1MTM3OTI1NiwiZXhwIjoyMDY2OTU1MjU2LCJpc3MiOiJwdWItMCIsInN1YiI6ImxpbmstcmVkaXJlY3QifQ.IHFhKKQWxroqN6E_kFp3iOJ5jGy2ZWvLyKdZXSk-2Cg?&utm_medium=email&utm_source=subscribe-widget-preamble&utm_content=166431233)

---

Consider [**DeepCoder**](https://substack.com/redirect/be9e207e-c851-4360-b79f-155510e97a1d?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), a 14 billion parameter coding model that achieves high performance across coding benchmarks. What makes DeepCoder notable is not just its size but its training methodology‚Äîreinforcement learning forms a core component of its development. The model uses a reward-based approach where it receives one point for passing all tests and zero for failing any, then iteratively improves through specialized reinforcement learning techniques. This exemplifies how post-training methods, particularly reinforcement learning, have become essential for creating capable AI systems. It underscores [a point made by observers like Andrej Karpathy](https://substack.com/redirect/67fa404f-c61a-4e0b-b198-437084131c10?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) in the context of coding tools: building modern AI requires fluency not just in traditional code and data, but in the craft of refining and specializing these powerful new models. The ML engineers who can fine-tune and distill models represent a critical piece of this evolving landscape.

#### The Art of Model Refinement

Post-training represents the crucial phase that transforms raw, pre-trained models into practical, deployable systems. While pre-training gives us powerful foundation models by processing vast amounts of text, these base models are essentially sophisticated next-token predictors. They lack the ability to follow instructions consistently, maintain conversation structure, or excel in specific domains without additional refinement.

The landscape of post-training encompasses two main paradigms. The first is **learning from demonstration**, where the model is fine-tuned on high-quality examples of a desired output, much like an apprentice mimicking a master. The second, and often more powerful, approach is **learning from reward**. Rather than mimicking a perfect example, the model learns to improve through trial and error, guided by a reward signal for successful outcomes. It does not need a perfect example to copy; it only needs a way to distinguish a better outcome from a worse one. Reinforcement learning is the engine for this paradigm.

The technical hurdles get much higher when an AI has to reason step-by-step and produce page-long answers. Reinforcement learning requires large batch sizes for stability, and each training iteration can take significant time and computational resources. The computational and engineering costs are the admission price for turning next-token prediction into reliable, context-aware assistance.

|     |                                                                                                                                                                                                                                                                                                                                                                              |     |
| --- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --- |
|     | [![](https://substackcdn.com/image/fetch/$s_!M4Ws!,w_1100,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e725d97-2d10-4a0e-87c0-2c30c2863732_1877x1029.jpeg)](https://substack.com/redirect/6f53fa72-1292-432c-b0af-a28ae9468570?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) |     |

This raises an important question about the relationship between capable agents and post-training. Even if future AI agents can effectively use external tools and resources‚Äîessentially scaled-up versions of the [text-to-SQL example](https://substack.com/redirect/d367a502-df84-4654-a239-d9a7212dcb5e?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) I described previously‚Äîpost-training remains a key differentiator. **External tools can provide factual grounding and a means of verification, but they cannot teach a model how to reason with nuance, navigate ambiguity, or decompose complex problems‚Äîskills that are critical for mastering **domain-specific** tasks**.

#### Making Advanced AI Accessible

Recent developments offer encouraging signs that sophisticated post-training techniques are becoming more accessible to smaller teams. [**NovaSky**](https://substack.com/redirect/8fa824b2-ef64-4ca6-b6c5-030e4d96e47a?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), an open-source initiative from Berkeley researchers, demonstrates how demonstration-based training can achieve near-GPT-4 level reasoning with surprisingly modest resources. Their [Sky-T1](https://substack.com/redirect/198aba35-194a-4ec1-9cc9-3b38282f8737?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) model matched OpenAI's o1-preview performance on mathematical and coding benchmarks using only 17,000 curated reasoning demonstrations and 19 hours of training on commodity hardware‚Äîroughly $450 in compute costs. This is why the project's true ambition is so critical: [**NovaSky**](https://substack.com/redirect/8fa824b2-ef64-4ca6-b6c5-030e4d96e47a?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) is building a full-stack platform for post-training, providing a toolkit needed to accelerate the industry‚Äôs shift from monolithic models to specialized agents.

While learning from demonstration is powerful, reinforcement learning unlocks the next level of capability, enabling models to tackle long-horizon tasks and improve through exploration. Here, the challenge has been one of scale and cost. [**Agentica**](https://substack.com/redirect/1baa4063-b9dc-4448-ae61-7441daa33d86?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), another open source project, has focused on building infrastructure that makes sophisticated reinforcement learning practical for more teams. By designing systems that cleverly disaggregate the components of training‚Äîseparating the model‚Äôs learning process from its interactions with a simulated environment‚Äîthey have reduced the cost and complexity of these techniques.

|     |                                                                                                                                                                                                                                                                                                                                                                             |     |
| --- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --- |
|     | [![](https://substackcdn.com/image/fetch/$s_!Z7IS!,w_1100,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7b7b185-73d7-42d5-8e26-89e8290d283d_1799x869.jpeg)](https://substack.com/redirect/3da35d7e-551e-4426-91ca-c32d18ebff5e?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) |     |

The focus on accessible, scalable, and open source tools is crucial because it decouples cutting-edge performance from specialized talent and colossal budgets. It allows smaller, more focused teams to refine highly effective models for their specific domains, whether for scientific discovery, specialized code generation, or optimizing internal business processes. This movement is making the most advanced AI techniques available to a wider array of builders, fostering a more diverse and competitive ecosystem.

#### The Path Forward

The current moment in AI development resembles an inflection point where assumptions are being reconsidered. The opportunity today isn‚Äôt to build a single, all-knowing AI that runs everything on its own. Instead, the most promising path lies in building products that feature practical, _partial_ autonomy. This means designing tight, collaborative loops where humans retain strategic control and provide judgment, while AI agents handle increasingly complex sub-tasks.

**Smaller agents can think and act faster in domain-specific settings**

To build these systems, we need more than just powerful base models. We need agents that are reliable, aligned with our goals, and specialized for the work at hand. **It is through the careful art of post-training‚Äîrefining, specializing, and guiding these models with techniques from supervised fine-tuning to reinforcement learning‚Äîthat we will forge the dependable, task-specific AI that defines this new era of computing**.

---

---

#### _If this playbook resonated, consider becoming a paid subscriber üôè_

[Upgrade to paid](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9ncmFkaWVudGZsb3cuc3Vic3RhY2suY29tL3N1YnNjcmliZT91dG1fc291cmNlPXBvc3QmdXRtX2NhbXBhaWduPWVtYWlsLWNoZWNrb3V0Jm5leHQ9aHR0cHMlM0ElMkYlMkZncmFkaWVudGZsb3cuc3Vic3RhY2suY29tJTJGcCUyRnlvdXItYWktcGxheWJvb2stZm9yLXRoZS1yZXN0LW9mJnI9NXM4M296JnRva2VuPWV5SjFjMlZ5WDJsa0lqb3pORGszTXpneE5qTXNJbWxoZENJNk1UYzFNVGs0TXpnMk5Td2laWGh3SWpveE56VTBOVGMxT0RZMUxDSnBjM01pT2lKd2RXSXRNakE1T0RNaUxDSnpkV0lpT2lKamFHVmphMjkxZENKOS50Y0pnOU4yN1BhNkg3eksyaEdTbTN6UzE1b3l3M3Y2Y19ZWWx0cWtSQlQ4IiwicCI6MTY3MDUyOTI2LCJzIjoyMDk4MywiZiI6dHJ1ZSwidSI6MzQ5NzM4MTYzLCJpYXQiOjE3NTE5ODM4NjUsImV4cCI6MjA2NzU1OTg2NSwiaXNzIjoicHViLTAiLCJzdWIiOiJsaW5rLXJlZGlyZWN0In0.OX0pL71_ATGx-gNNM-sosJ9JOoN3-q_W0tO6QAYhD_4?&utm_medium=email&utm_source=substack&utm_content=postcta)

---

|     |                                                                                                                                                                                                                                                                                                                                                                              |     |
| --- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --- |
|     | [![](https://substackcdn.com/image/fetch/$s_!LqaL!,w_1100,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c0d47b-2c31-4172-9e3f-a83e4ce0f0b2_5795x4368.jpeg)](https://substack.com/redirect/56898e06-e2ee-43d5-9dc7-47b4cf947d47?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) |     |

Derived from [**"Navigating the path to AI success"**](https://substack.com/redirect/6578dfe9-b316-4445-9e96-79142566506b?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) ; [**click to enlarge**](https://substack.com/redirect/feb4762d-94f6-4939-8c28-9bd94fcc82c4?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8).

---

_[**Ben Lorica**](https://substack.com/redirect/01069103-5faf-4c10-8633-7a55aa4755dc?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) edits the [Gradient Flow newsletter](https://substack.com/redirect/1487ca53-ed62-43bc-87e8-b711c6ed6170?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8). He helps organize the [**AI Conference**](https://substack.com/redirect/eb6097c1-7f4a-4ffc-95ff-622898e53d93?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), the [**AI Agent Conference**](https://substack.com/redirect/67ac5c52-a78c-45cf-bb43-e6ff1f125b7e?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), the [**Applied AI Summit**](https://substack.com/redirect/c974c349-eac4-4a30-afbf-cb3a81d8493f?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), while also serving as the Strategic Content Chair for AI at the [**Linux Foundation**](https://substack.com/redirect/cee47eb0-e155-4ba2-abcb-42afa72e6970?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8). He is the host of [the Data Exchange podcast](https://substack.com/redirect/bf91c4e9-4257-453e-b23e-f8f8753f99ec?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8). You can follow him on [Linkedin](https://substack.com/redirect/4ddc0157-7814-4bcf-ad47-7c12cbb38570?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), [Mastodon](https://substack.com/redirect/32314e88-1368-4a26-b3d0-0583e84a7255?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), [Reddit](https://substack.com/redirect/e63e1f6c-f605-4ec6-b9b8-85a6650dd4da?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), [Bluesky](https://substack.com/redirect/c237762a-ff23-481a-a4bf-cfe01faab71e?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), [YouTube](https://substack.com/redirect/90536cfb-7d57-48b2-b37a-b3cb66c4585f?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), or [TikTok](https://substack.com/redirect/bfb1a83e-323b-43d5-aece-e9e692e97c9f?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8). This newsletter is produced by [Gradient Flow](https://substack.com/redirect/58a65813-1937-45e5-8fde-bafe9e4627c0?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8)._

You're currently a free subscriber to [Gradient Flow](https://substack.com/redirect/1487ca53-ed62-43bc-87e8-b711c6ed6170?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8). For the full experience, [upgrade your subscription.](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9ncmFkaWVudGZsb3cuc3Vic3RhY2suY29tL3N1YnNjcmliZT91dG1fc291cmNlPXBvc3QmdXRtX2NhbXBhaWduPWVtYWlsLWNoZWNrb3V0Jm5leHQ9aHR0cHMlM0ElMkYlMkZncmFkaWVudGZsb3cuc3Vic3RhY2suY29tJTJGcCUyRmJ1aWxkaW5nLWJldHRlci1haS1hZ2VudHMtZm9yLWxlc3Mmcj01czgzb3omdG9rZW49ZXlKMWMyVnlYMmxrSWpvek5EazNNemd4TmpNc0ltbGhkQ0k2TVRjMU1UTTNPVEkxTml3aVpYaHdJam94TnpVek9UY3hNalUyTENKcGMzTWlPaUp3ZFdJdE1qQTVPRE1pTENKemRXSWlPaUpqYUdWamEyOTFkQ0o5LmU3UXhGZWV1Q01PVG4zbnBhMW5mT2ZiZmN4LWd4N1hrdHhaVkRoU2RVWTQiLCJwIjoxNjY0MzEyMzMsInMiOjIwOTgzLCJmIjp0cnVlLCJ1IjozNDk3MzgxNjMsImlhdCI6MTc1MTM3OTI1NiwiZXhwIjoyMDY2OTU1MjU2LCJpc3MiOiJwdWItMCIsInN1YiI6ImxpbmstcmVkaXJlY3QifQ.IHFhKKQWxroqN6E_kFp3iOJ5jGy2ZWvLyKdZXSk-2Cg?&utm_source=substack&utm_medium=email&utm_content=postcta)

[Upgrade to paid](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9ncmFkaWVudGZsb3cuc3Vic3RhY2suY29tL3N1YnNjcmliZT91dG1fc291cmNlPXBvc3QmdXRtX2NhbXBhaWduPWVtYWlsLWNoZWNrb3V0Jm5leHQ9aHR0cHMlM0ElMkYlMkZncmFkaWVudGZsb3cuc3Vic3RhY2suY29tJTJGcCUyRmJ1aWxkaW5nLWJldHRlci1haS1hZ2VudHMtZm9yLWxlc3Mmcj01czgzb3omdG9rZW49ZXlKMWMyVnlYMmxrSWpvek5EazNNemd4TmpNc0ltbGhkQ0k2TVRjMU1UTTNPVEkxTml3aVpYaHdJam94TnpVek9UY3hNalUyTENKcGMzTWlPaUp3ZFdJdE1qQTVPRE1pTENKemRXSWlPaUpqYUdWamEyOTFkQ0o5LmU3UXhGZWV1Q01PVG4zbnBhMW5mT2ZiZmN4LWd4N1hrdHhaVkRoU2RVWTQiLCJwIjoxNjY0MzEyMzMsInMiOjIwOTgzLCJmIjp0cnVlLCJ1IjozNDk3MzgxNjMsImlhdCI6MTc1MTM3OTI1NiwiZXhwIjoyMDY2OTU1MjU2LCJpc3MiOiJwdWItMCIsInN1YiI6ImxpbmstcmVkaXJlY3QifQ.IHFhKKQWxroqN6E_kFp3iOJ5jGy2ZWvLyKdZXSk-2Cg?&utm_source=substack&utm_medium=email&utm_content=postcta)

[![](https://substackcdn.com/image/fetch/$s_!PeVs!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Ficon%2FLucideHeart%3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke%3D%2523808080%26strokeWidth%3D2)Like](https://substack.com/app-link/post?publication_id=20983&post_id=166431233&utm_source=substack&isFreemail=true&submitLike=true&token=eyJ1c2VyX2lkIjozNDk3MzgxNjMsInBvc3RfaWQiOjE2NjQzMTIzMywicmVhY3Rpb24iOiLinaQiLCJpYXQiOjE3NTEzNzkyNTYsImV4cCI6MTc1Mzk3MTI1NiwiaXNzIjoicHViLTIwOTgzIiwic3ViIjoicmVhY3Rpb24ifQ.kos4-l4s4bcwp_e71cx5aBlczecRyckPLE6NhWntV2Q&utm_medium=email&utm_campaign=email-reaction&r=5s83oz)

[![](https://substackcdn.com/image/fetch/$s_!x1tS!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Ficon%2FLucideComments%3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke%3D%2523808080%26strokeWidth%3D2)Comment](https://substack.com/app-link/post?publication_id=20983&post_id=166431233&utm_source=substack&utm_medium=email&isFreemail=true&comments=true&token=eyJ1c2VyX2lkIjozNDk3MzgxNjMsInBvc3RfaWQiOjE2NjQzMTIzMywiaWF0IjoxNzUxMzc5MjU2LCJleHAiOjE3NTM5NzEyNTYsImlzcyI6InB1Yi0yMDk4MyIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.pP-4VJxL7MnqRBUBulrDKODPC_O8Cx44wdOq__W5_hY&r=5s83oz&utm_campaign=email-half-magic-comments&action=post-comment&utm_source=substack&utm_medium=email)

[![](https://substackcdn.com/image/fetch/$s_!5EGt!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Ficon%2FNoteForwardIcon%3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke%3D%2523808080%26strokeWidth%3D2)Restack](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9vcGVuLnN1YnN0YWNrLmNvbS9wdWIvZ3JhZGllbnRmbG93L3AvYnVpbGRpbmctYmV0dGVyLWFpLWFnZW50cy1mb3ItbGVzcz91dG1fc291cmNlPXN1YnN0YWNrJnV0bV9tZWRpdW09ZW1haWwmdXRtX2NhbXBhaWduPWVtYWlsLXJlc3RhY2stY29tbWVudCZhY3Rpb249cmVzdGFjay1jb21tZW50JnI9NXM4M296JnRva2VuPWV5SjFjMlZ5WDJsa0lqb3pORGszTXpneE5qTXNJbkJ2YzNSZmFXUWlPakUyTmpRek1USXpNeXdpYVdGMElqb3hOelV4TXpjNU1qVTJMQ0psZUhBaU9qRTNOVE01TnpFeU5UWXNJbWx6Y3lJNkluQjFZaTB5TURrNE15SXNJbk4xWWlJNkluQnZjM1F0Y21WaFkzUnBiMjRpZlEucFAtNFZKeEw3TW5xUkJVQnVsckRLT0RQQ19POEN4NDR3ZE9xX19XNV9oWSIsInAiOjE2NjQzMTIzMywicyI6MjA5ODMsImYiOnRydWUsInUiOjM0OTczODE2MywiaWF0IjoxNzUxMzc5MjU2LCJleHAiOjIwNjY5NTUyNTYsImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9.YQP5ONeYmVA2cVUSKWt1un5f4dl1q4bRSQCz6O_hO-I?&utm_source=substack&utm_medium=email)

¬© 2025 Gradient Flow  
548 Market Street PMB 72296, San Francisco, CA 94104  
[Unsubscribe](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9ncmFkaWVudGZsb3cuc3Vic3RhY2suY29tL2FjdGlvbi9kaXNhYmxlX2VtYWlsP3Rva2VuPWV5SjFjMlZ5WDJsa0lqb3pORGszTXpneE5qTXNJbkJ2YzNSZmFXUWlPakUyTmpRek1USXpNeXdpYVdGMElqb3hOelV4TXpjNU1qVTJMQ0psZUhBaU9qRTNPREk1TVRVeU5UWXNJbWx6Y3lJNkluQjFZaTB5TURrNE15SXNJbk4xWWlJNkltUnBjMkZpYkdWZlpXMWhhV3dpZlEuUi1hUnNEX1p0VVpUQ08zQThGQmktNV9uQ2pseFpmaDdJTlVQZVg0bjZ4NCIsInAiOjE2NjQzMTIzMywicyI6MjA5ODMsImYiOnRydWUsInUiOjM0OTczODE2MywiaWF0IjoxNzUxMzc5MjU2LCJleHAiOjIwNjY5NTUyNTYsImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9._f7F0oG-QvfbnLOV7SJ71lIuHxpPlWZTg2VUqWfBX_0?)

[![Get the app](https://substackcdn.com/image/fetch/$s_!IzGP!,w_262,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Femail%2Fgeneric-app-button%402x.png)](https://substack.com/redirect/aecb4aa3-890e-43d8-8ec8-ee6e7c7278e7?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8)[![Start writing](https://substackcdn.com/image/fetch/$s_!LkrL!,w_270,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Femail%2Fpublish-button%402x.png)](https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9zdWJzdGFjay5jb20vc2lnbnVwP3V0bV9zb3VyY2U9c3Vic3RhY2smdXRtX21lZGl1bT1lbWFpbCZ1dG1fY29udGVudD1mb290ZXImdXRtX2NhbXBhaWduPWF1dG9maWxsZWQtZm9vdGVyJmZyZWVTaWdudXBFbWFpbD1zdW1pdHVwLmRldkBnbWFpbC5jb20mcj01czgzb3oiLCJwIjoxNjY0MzEyMzMsInMiOjIwOTgzLCJmIjp0cnVlLCJ1IjozNDk3MzgxNjMsImlhdCI6MTc1MTM3OTI1NiwiZXhwIjoyMDY2OTU1MjU2LCJpc3MiOiJwdWItMCIsInN1YiI6ImxpbmstcmVkaXJlY3QifQ.nndT8amAD1WVwGOGHiDjGd1TlWSYn8arGiNpt829IMg?)

![](https://eotrx.substackcdn.com/open?token=eyJtIjoiPDIwMjUwNzAxMTQwNTE4LjMuY2YyNmRhODJkNGFkMDFkOUBtZzIuc3Vic3RhY2suY29tPiIsInUiOjM0OTczODE2MywiciI6InN1bWl0dXAuZGV2QGdtYWlsLmNvbSIsImQiOiJtZzIuc3Vic3RhY2suY29tIiwicCI6MTY2NDMxMjMzLCJ0IjoibmV3c2xldHRlciIsImEiOiJldmVyeW9uZSIsInMiOjIwOTgzLCJjIjoicG9zdCIsImYiOnRydWUsInBvc2l0aW9uIjoiYm90dG9tIiwiaWF0IjoxNzUxMzc5MjU2LCJleHAiOjE3NTM5NzEyNTYsImlzcyI6InB1Yi0wIiwic3ViIjoiZW8ifQ.8-5VsL6CGfHwVhnKnuNTAnbhJXRx8Pd24jU7I70oDXk)![](https://email.mg2.substack.com/o/eJw80N2OgyAQhuGrKYeGf_WAazEjjC5ZAQNDG-9-Y9vs6TfJmyfjgXAv9XJnacSC00FMZmLoxGiEGmdpLcME8Vh2zFiBMCxA_1djlTDsx6mZGyu1N-O4bgECbOO0CaulMkJs4Fl0kkvDRy6E5kZMgxr8Jm2ASQYNgYswPzRPuxxaXxuB_x18SSy2Zav4BjiqHdnNXKCHiNmjwyfWq-TvHIMT1molpFKfha4TXcZXO5AIKzv7uviSUs-RrgUzrAeGb7ivR_RAseQ7JPk8KVZd6ylSP4eAz4fm-w15w1pfQ0kQs9sr3BrajvJi9Pljb1jvitLzqCZhFXs6-RcAAP__-ft4ng)
```

<END_EXAMPLE_INPUT>

## Output Cleaned Newsletter:

<START_EXAMPLE_OUTPUT>

```md
# [Building better AI agents, for less](https://substack.com/app-link/post?publication_id=20983&post_id=166431233&utm_source=post-email-title&utm_campaign=email-post-title&isFreemail=true&r=5s83oz&token=eyJ1c2VyX2lkIjozNDk3MzgxNjMsInBvc3RfaWQiOjE2NjQzMTIzMywiaWF0IjoxNzUxMzc5MjU2LCJleHAiOjE3NTM5NzEyNTYsImlzcyI6InB1Yi0yMDk4MyIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.pP-4VJxL7MnqRBUBulrDKODPC_O8Cx44wdOq__W5_hY)

[Ben Lorica ÁΩóÁëûÂç°](https://substack.com/@gradientflow)

Jul 1

[![](https://substackcdn.com/image/fetch/$s_!Qpug!,w_1100,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0f732fb8-bcb3-47bb-93e0-cf2c6c0653c5_1100x220.png)](https://substack.com/redirect/764cedaa-73ec-495a-ab5e-21f3fe11d8b9?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8)

**[Subscribe](https://substack.com/redirect/f40d9219-3f21-45f9-a001-79f89d2da44d?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) ‚Ä¢ [Previous Issues](https://substack.com/redirect/1487ca53-ed62-43bc-87e8-b711c6ed6170?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8)**

# **From Monoliths to Specialists: The New Era of AI**

In a [previous analysis](https://substack.com/redirect/bbef10a2-4f85-45f6-a22a-ffcc586980fd?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), I examined how a company could build a highly effective AI application for writing database queries _without_ any fine-tuning, relying instead on semantic catalogs and validation loops to mirror how experienced analysts write SQL. This approach worked exceptionally well for that specific, targeted application. However, it represents just one narrow slice of what AI can accomplish.

For businesses deploying AI, the forward-looking vision is a shift away from giant pre-trained models and toward ecosystems of smaller, specialized agents. With open foundation models rapidly closing the gap on proprietary ones, the key differentiator is no longer scale, but specialization. Smaller agents can think and act faster in domain-specific settings, much like how the power of a modern smartphone comes not from the device itself, but from its ecosystem of countless specialized apps, each designed for a specific purpose.

Consider [**DeepCoder**](https://substack.com/redirect/be9e207e-c851-4360-b79f-155510e97a1d?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), a 14 billion parameter coding model that achieves high performance across coding benchmarks. What makes DeepCoder notable is not just its size but its training methodology‚Äîreinforcement learning forms a core component of its development. The model uses a reward-based approach where it receives one point for passing all tests and zero for failing any, then iteratively improves through specialized reinforcement learning techniques. This exemplifies how post-training methods, particularly reinforcement learning, have become essential for creating capable AI systems. It underscores [a point made by observers like Andrej Karpathy](https://substack.com/redirect/67fa404f-c61a-4e0b-b198-437084131c10?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) in the context of coding tools: building modern AI requires fluency not just in traditional code and data, but in the craft of refining and specializing these powerful new models. The ML engineers who can fine-tune and distill models represent a critical piece of this evolving landscape.

#### The Art of Model Refinement

Post-training represents the crucial phase that transforms raw, pre-trained models into practical, deployable systems. While pre-training gives us powerful foundation models by processing vast amounts of text, these base models are essentially sophisticated next-token predictors. They lack the ability to follow instructions consistently, maintain conversation structure, or excel in specific domains without additional refinement.

The landscape of post-training encompasses two main paradigms. The first is **learning from demonstration**, where the model is fine-tuned on high-quality examples of a desired output, much like an apprentice mimicking a master. The second, and often more powerful, approach is **learning from reward**. Rather than mimicking a perfect example, the model learns to improve through trial and error, guided by a reward signal for successful outcomes. It does not need a perfect example to copy; it only needs a way to distinguish a better outcome from a worse one. Reinforcement learning is the engine for this paradigm.

The technical hurdles get much higher when an AI has to reason step-by-step and produce page-long answers. Reinforcement learning requires large batch sizes for stability, and each training iteration can take significant time and computational resources. The computational and engineering costs are the admission price for turning next-token prediction into reliable, context-aware assistance.

|     |                                                                                                                                                                                                                                                                                                                                                                              |     |
| --- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --- |
|     | [![](https://substackcdn.com/image/fetch/$s_!M4Ws!,w_1100,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e725d97-2d10-4a0e-87c0-2c30c2863732_1877x1029.jpeg)](https://substack.com/redirect/6f53fa72-1292-432c-b0af-a28ae9468570?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) |     |

This raises an important question about the relationship between capable agents and post-training. Even if future AI agents can effectively use external tools and resources‚Äîessentially scaled-up versions of the [text-to-SQL example](https://substack.com/redirect/d367a502-df84-4654-a239-d9a7212dcb5e?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) I described previously‚Äîpost-training remains a key differentiator. **External tools can provide factual grounding and a means of verification, but they cannot teach a model how to reason with nuance, navigate ambiguity, or decompose complex problems‚Äîskills that are critical for mastering **domain-specific** tasks**.

#### Making Advanced AI Accessible

Recent developments offer encouraging signs that sophisticated post-training techniques are becoming more accessible to smaller teams. [**NovaSky**](https://substack.com/redirect/8fa824b2-ef64-4ca6-b6c5-030e4d96e47a?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), an open-source initiative from Berkeley researchers, demonstrates how demonstration-based training can achieve near-GPT-4 level reasoning with surprisingly modest resources. Their [Sky-T1](https://substack.com/redirect/198aba35-194a-4ec1-9cc9-3b38282f8737?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) model matched OpenAI's o1-preview performance on mathematical and coding benchmarks using only 17,000 curated reasoning demonstrations and 19 hours of training on commodity hardware‚Äîroughly $450 in compute costs. This is why the project's true ambition is so critical: [**NovaSky**](https://substack.com/redirect/8fa824b2-ef64-4ca6-b6c5-030e4d96e47a?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) is building a full-stack platform for post-training, providing a toolkit needed to accelerate the industry‚Äôs shift from monolithic models to specialized agents.

While learning from demonstration is powerful, reinforcement learning unlocks the next level of capability, enabling models to tackle long-horizon tasks and improve through exploration. Here, the challenge has been one of scale and cost. [**Agentica**](https://substack.com/redirect/1baa4063-b9dc-4448-ae61-7441daa33d86?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), another open source project, has focused on building infrastructure that makes sophisticated reinforcement learning practical for more teams. By designing systems that cleverly disaggregate the components of training‚Äîseparating the model‚Äôs learning process from its interactions with a simulated environment‚Äîthey have reduced the cost and complexity of these techniques.

|     |                                                                                                                                                                                                                                                                                                                                                                             |     |
| --- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --- |
|     | [![](https://substackcdn.com/image/fetch/$s_!Z7IS!,w_1100,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7b7b185-73d7-42d5-8e26-89e8290d283d_1799x869.jpeg)](https://substack.com/redirect/3da35d7e-551e-4426-91ca-c32d18ebff5e?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) |     |

The focus on accessible, scalable, and open source tools is crucial because it decouples cutting-edge performance from specialized talent and colossal budgets. It allows smaller, more focused teams to refine highly effective models for their specific domains, whether for scientific discovery, specialized code generation, or optimizing internal business processes. This movement is making the most advanced AI techniques available to a wider array of builders, fostering a more diverse and competitive ecosystem.

#### The Path Forward

The current moment in AI development resembles an inflection point where assumptions are being reconsidered. The opportunity today isn‚Äôt to build a single, all-knowing AI that runs everything on its own. Instead, the most promising path lies in building products that feature practical, _partial_ autonomy. This means designing tight, collaborative loops where humans retain strategic control and provide judgment, while AI agents handle increasingly complex sub-tasks.

**Smaller agents can think and act faster in domain-specific settings**

To build these systems, we need more than just powerful base models. We need agents that are reliable, aligned with our goals, and specialized for the work at hand. **It is through the careful art of post-training‚Äîrefining, specializing, and guiding these models with techniques from supervised fine-tuning to reinforcement learning‚Äîthat we will forge the dependable, task-specific AI that defines this new era of computing**.

---

|     |                                                                                                                                                                                                                                                                                                                                                                              |     |
| --- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --- |
|     | [![](https://substackcdn.com/image/fetch/$s_!LqaL!,w_1100,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c0d47b-2c31-4172-9e3f-a83e4ce0f0b2_5795x4368.jpeg)](https://substack.com/redirect/56898e06-e2ee-43d5-9dc7-47b4cf947d47?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) |     |

Derived from [**"Navigating the path to AI success"**](https://substack.com/redirect/6578dfe9-b316-4445-9e96-79142566506b?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) ; [**click to enlarge**](https://substack.com/redirect/feb4762d-94f6-4939-8c28-9bd94fcc82c4?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8).

---

_[**Ben Lorica**](https://substack.com/redirect/01069103-5faf-4c10-8633-7a55aa4755dc?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8) edits the [Gradient Flow newsletter](https://substack.com/redirect/1487ca53-ed62-43bc-87e8-b711c6ed6170?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8). He helps organize the [**AI Conference**](https://substack.com/redirect/eb6097c1-7f4a-4ffc-95ff-622898e53d93?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), the [**AI Agent Conference**](https://substack.com/redirect/67ac5c52-a78c-45cf-bb43-e6ff1f125b7e?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), the [**Applied AI Summit**](https://substack.com/redirect/c974c349-eac4-4a30-afbf-cb3a81d8493f?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), while also serving as the Strategic Content Chair for AI at the [**Linux Foundation**](https://substack.com/redirect/cee47eb0-e155-4ba2-abcb-42afa72e6970?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8). He is the host of [the Data Exchange podcast](https://substack.com/redirect/bf91c4e9-4257-453e-b23e-f8f8753f99ec?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8). You can follow him on [Linkedin](https://substack.com/redirect/4ddc0157-7814-4bcf-ad47-7c12cbb38570?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), [Mastodon](https://substack.com/redirect/32314e88-1368-4a26-b3d0-0583e84a7255?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), [Reddit](https://substack.com/redirect/e63e1f6c-f605-4ec6-b9b8-85a6650dd4da?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), [Bluesky](https://substack.com/redirect/c237762a-ff23-481a-a4bf-cfe01faab71e?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), [YouTube](https://substack.com/redirect/90536cfb-7d57-48b2-b37a-b3cb66c4585f?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8), or [TikTok](https://substack.com/redirect/bfb1a83e-323b-43d5-aece-e9e692e97c9f?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8). This newsletter is produced by [Gradient Flow](https://substack.com/redirect/58a65813-1937-45e5-8fde-bafe9e4627c0?j=eyJ1IjoiNXM4M296In0.tGNGSdtmlCx12UO5VTFY50vjzjDXKZsMTxKEYVZUdc8)._

¬© 2025 Gradient Flow  
548 Market Street PMB 72296, San Francisco, CA 94104
```

<END_EXAMPLE_OUTPUT>
